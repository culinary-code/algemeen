# General Introduction

Welcome to the Culinary Code app. Culinary Code helps users efficiently manage meals and groceries with a user-friendly interface. This repo provides you with the necessary tools to do two out of our three intended uses:

- [ ] Utilize our own backend api with a small fee to utilize the services
- [x] Spin up your own backend api service and use your own openAI key for all AI services
- [x] Spin up your own backend api service, spin up a local LLM to replace the openAI services (success not guaranteed)   

To see what features the application currently has, visit [[Features]]

To see what features are currently planned, visit [[Planned_Features]]

To help develop these features, look at [[How_To]]


# Features

The application currently has the following features:

- Logging into a Keycloak account
- Registering a new Keycloak account
- Browsing recipes based on recipe names and other filters like: cooktime, difficulty, ingredients
- Viewing recipes in detail
- Adding reviews to recipes
- Creating new recipes based on a chatgpt prompt: supported identifiers include recipe name, ingredients, cooking time, difficulty, preferences
- Viewing and managing favorite recipes
- Adding recipes to a mealplanner
- Viewing and managing a grocery list, this is linked to the mealplanner.
- Managing Account settings: preferences that automatically get added to prompts, family size

# Planned Features

The application currently has the following features planned: 

- Groups which have their own mealplanner and grocerylist
- Being able to edit recipes after they are created
- Adding your own recipes to the app database
- Adding images to the recipes to show others your creations
- Support for other languages than dutch
- Being able to change the difficulty of a recipe based on user feedback
- Functionality based on groups like marking attendance to a meal
- Being able to manage what ingredients you already have and automatically using those to create new recipes

# Keycloak

- ## Custom Set up without import file

  When you have the docker image running locally or in the cloud, go to the address provided in the docker compose file or the url in the cloud. You should see a login screen.
  1. Log in as admin. In the provided docker file the name and password are both admin, but it is recommended to change those values
  2. On the top left you should see a dropdown menu that is currently set to the master realm
  3. Click on that dropdown menu and create a new realm
  5. Use the name you have given in the environment variables for both the front-end and back-end project. see [[Environment_Variables]]

- ## Necessary Users
  This is used only for local development. If you want to only use the application on a local environment, you can skip this step.
  1. Go to the user tab, this should be visible on the left hand side
  2. Create a new user. This will become the admin user with rights to create new accounts. 
  3. After creation of the user, go to the credentials tab of that user (at the top) and create a new password. Set "temporary" to off.
  4. Go to the role management tab of the user (at the top)
  5. Give the user the following roles:
        - realm-admin
        - manage-account-links
        - manage-account
        - view-profile
  6. The user should be all set up

# Deploying to Azure

- ## GPT
For the deployment of the GPT model, we make use of Azure OpenAI Service. You can set up an OpenAI service on Azure using the following link:

https://portal.azure.com/#view/Microsoft_Azure_ProjectOxford/CognitiveServicesHub/~/OpenAI

We used the GPT-4o Mini model for this project. A breakdown of why we chose this model can be found at [[Recommended_LLM_Model]].

Once the service is set up, you can get the API key and endpoint from the Azure portal and set them as environment variables in the backend application.

- ## Image generator
For recipe image generation, we make use of a DALL-E 3 deployment on Azure. You can set up a DALL-E 3 model deployment on Azure OpenAI Studio.

Once the service is set up, you can get the API key and endpoint from the Azure portal and set them as environment variables in the backend application.

- ## Blob storage
Azure Blob storage is used to store images generated by the DALL-E 3 model. You can set up a Blob storage on Azure using the following link: [https://portal.azure.com/#create/Microsoft.StorageAccount](https://portal.azure.com/#create/Microsoft.StorageAccount)

Once the Blob storage is set up, you can get the connection string and container name from the Azure portal and set them as environment variables in the backend application.

Ensure that the MIME type of the images generated by the DALL-E 3 model is set to "image/png" before uploading them to the Blob storage.

Also ensure you configure the CORS settings of the Blob storage to allow requests from the backend application. As well as the public access level of the container to allow public access to the images.

- ## Database
Azure PostgreSQL database - Flexible server

You can set up a PostgreSQL database on Azure using the following link: [https://portal.azure.com/#browse/Microsoft.DBforPostgreSQL%2FflexibleServers](https://portal.azure.com/#create/Microsoft.PostgreSQLFlexibleServer)

Configure the specifications based on your development or production needs.

Create a new user role on the database with restricted permissions to use from the backend application.

- ## Keycloak
When you set up Keycloak, you can export the currently configured realm into a json file, check out the documentation around exporting here: [Importing and Exporting Realms](https://www.keycloak.org/server/importExport)

Then you can make a Dockerfile where you pull in the base Keycloak image and add your own ENTRYPOINT command where you set up import realm.
```Dockerfile
FROM quay.io/keycloak/keycloak:25.0.5

RUN mkdir -p /opt/keycloak/data/import
COPY ./realm-export.json /opt/keycloak/data/import

EXPOSE 8080

ENTRYPOINT ["/opt/keycloak/bin/kc.sh", "-v", "start-dev", "--import-realm"]
```

Then you can build and push the Docker image to Docker hub for example.
```bash
docker build -t steffenvochten/culinarycode_idp:latest .  # tag latest so you don't have to delete and recreate the container instance on Azure for image changes
docker push steffenvochten/culinarycode_idp:latest
```

Now on Azure you can set up a Container Instance which will pull and run your Docker image in the cloud.

If you tag your docker image with latest, you can push changes to the image to docker hub, without having to delete and recreate the Container Instance, since its settings can't be changed.

Set up a Container Instance on Azure using the following link https://portal.azure.com/#browse/Microsoft.ContainerInstance%2FcontainerGroups

- ## Backend

To deploy the app on Azure we make use of the Azure App Service.

To create a Web App on Azure, use this link: https://portal.azure.com/#create/Microsoft.WebSite

The runtime stack the backend application uses is .NET 8. The target operating system is Linux.

Once the Web App is set up on Azure, we can push our backend application to this Web App.

First, navigate to the application's root folder, then follow these steps:
```bash
cd .\WEBAPI\
dotnet publish -c Release -r linux-x64 --self-contained false -o ./publish
cd .\publish\
zip -r ../culinarycode.zip .
az webapp deployment source config-zip --resource-group rg-stage24-webchefs --name culinarycode --src culinarycode.zip
```

You can view application logs using this command:
```bash
az webapp log tail --name culinarycode --resource-group rg-stage24-webchefs
```

Finally ensure that all the environment variables are properly set up in the Web App settings on Azure, ensure that you point the environment variables for the database and Keycloak container URLs point to the proper Azure service URLs.

# Deploying to a (virtual) machine

If you only care about putting the application online on your own system or a vm in the cloud and donâ€™t want to bother with any development, we got you covered.

### Required Knowledge:
- Navigating a Linux server
- Editing a file
- Docker Compose

---

## What This Guide Covers:
1. Using the provided Docker Compose YAML file to easily set up your own services.
2. Getting a simple domain name for your server.
3. Getting and setting up HTTPS certificates.
4. Setting up a reverse proxy NGINX implementation to link requests to the right service.

### What is Not Included in This Version:
- Using blob storage for images, see **[[Blob Storage]]**.

---

## Using the Provided Docker Compose File

The provided Compose file relies on images publicly available on Docker Hub. This means that if you want to use this method for images other than the latest version, you have to change the links at `image` for both `idp_keycloak` and `backend`.

### Inside the Docker Network
There are four different containers:
1. **Keycloak container** with a custom image for a necessary admin user (`idp_keycloak`).
2. **Postgres (Alpine version)** database for everything related to the Keycloak container (`idp_postgres`).
3. **Backend container** for running the back-end image (`backend`).
4. **Postgres database** container for everything related to the back-end container (`postgres`).

### Important Steps:
1. Change out the environment variables for each container pertaining to usernames, passwords, and database names. 
2. Ensure these changes reflect in the corresponding environment variables in other containers.

#### Keycloak Environment Variables:
- Username, database name, and password for the IDP database container must be reflected in:
  - `KC_DB_USERNAME`
  - `KC_DB_PASSWORD`
  - `KC_DB_URL_DATABASE`

#### Backend Environment Variables:
- Username, database name, and password for the backend database container must be reflected in `Database__ConnectionString`.
- **Keycloak Admin Credentials**: Use `KEYCLOAK_ADMIN` and `KEYCLOAK_ADMIN_PASSWORD` logging into the admin console, Change these for your own values.
- **Optional Variables**:
  - To disable image generation, set the `ImageGeneration` variable to `false`.
  - For Azure storage, update the connection string with your details.
  - Email service can remain blank if unused.

#### Cronjob Details:
- Used for automatic database updates:
  - Modify the `MinimumAmount` variable to control recipe creation. At the specified time in the schedule, the backend will run a job to fill up the database to that amount and delete unused recipes.
  - Set the `CronSchedule` variable using standard cron syntax. Look up how to edit these values. Currently it is set to run at 2 AM every day. This is dependent on your device time.

---

## Getting a Domain Name for Your Server

To make your server publicly accessible, you will need two domain names:
1. One for the back-end service (**domain1**).
2. One for the Keycloak identity provider (**domain2**).

Both domains should point to the same IP address of your (Virtual) Machine. Follow these steps:

1. Use a service like **Duck DNS** for free domain names or any other domain name provider.
2. Update the environment variables in the Docker containers:
   - Set `Keycloak__FrontendUrl` in the backend container to the domain reserved for Keycloak.

---

## Getting and Setting Up HTTPS Certificates

### Prerequisites:
- Ensure Docker Compose is running, and your domain names point to the correct IP address.

## Getting and Setting Up HTTPS Certificates

We are about to ensure the services can run over HTTPS and are trusted by mobile devices. We will accomplish this using a tool called Certbot. Before proceeding, we need to install NGINX because Certbot will detect its installation and automatically adjust some files.

To install NGINX, run the following commands:

```bash
sudo apt-get update
sudo apt-get install nginx
```

To install Certbot onto your device, run the following command:

```bash
sudo apt install certbot python3-certbot-nginx
```

After installation, create your certificates (replace `domain1` and `domain2` with your actual domain names):

```bash
sudo certbot --nginx -d domain1 -d domain2
```

This command should return the location of the newly created certificates. Keep this location in mind for the next step.

---

## Setting Up a Reverse Proxy NGINX Implementation to Link Requests to the Right Service

Navigate to the location provided by the previous Certbot command. For example: `/etc/nginx/sites-available/`. Edit the `default` file. While the file may already include a lot of data, you can leave most of it out. Ensure the file includes the links to the `ssl_certificate` and `ssl_certificate_key` automatically added by Certbot. Make sure to copy these values.

This file contains the configuration to set up the reverse proxy. The goal is to direct incoming requests:
- **Domain1** should link to the Back-end container.
- **Domain2** should link to the Keycloak container.

Below is a sample configuration file you can copy and paste. Replace the placeholders (`domain1`, `domain2`) with your actual domain names:

```nginx
# Set-up of the back-end service. Any requests coming in on domain1 will be forwarded to the correct port. Change out domain1 for your actual domain name.
server {
    listen 443 ssl; 
    server_name domain1;

    ssl_certificate /etc/letsencrypt/live/domain1/fullchain.pem; # managed by Certbot
    ssl_certificate_key /etc/letsencrypt/live/domain1/privkey.pem; # managed by Certbot
    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot
    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot

    location / {
        proxy_pass http://localhost:5114;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}

# Set-up of the keycloak service. any requests coming in on domain2 will be forwarded to the correct port. Change out domain2 for your actual domain name.
server {
    listen 443 ssl; # managed by Certbot
    server_name domain2;

    ssl_certificate /etc/letsencrypt/live/domain2/fullchain.pem; # managed by Certbot
    ssl_certificate_key /etc/letsencrypt/live/domain2/privkey.pem; # managed by Certbot
    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot
    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot

    location / {
        proxy_pass http://localhost:8180;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}

# This will redirect http requests to https requests when they are made to the right domain names. Change out domain1 and domain2 for the actual 
server {
    if ($host = domain2) {
        return 301 https://$host$request_uri;
    } # managed by Certbot


    if ($host = domain1) {
        return 301 https://$host$request_uri;
    } # managed by Certbot


        listen 80 ;
        listen [::]:80 ;
    server_name domain2 domain1;
    return 404; # managed by Certbot

}
```
# Running everything locally

## Running docker

Explain docker here...

## Recommended LLM Model

After extensive testing, we recommend using the GPT-4o Mini model (version: 2024-07-18) for this project. This model has consistently delivered reliable and accurate results, meeting our specific requirements.

While we also tested GPT-3.5 Turbo, we found its reliability to be significantly lower, particularly in non-English languages. Since our development and testing focus on a Dutch-speaking user base, the GPT-4o Mini model proved far superior in handling these language-specific needs.

Additionally, we tested several local LLMs, but found that the output from smaller models was not reliable, with significant inconsistencies in performance. Larger models might offer better reliability, but they require significantly higher computational resources. Running them efficiently would demand high-end hardware, which may not be practical for all setups.

For users opting for local hosting, we recommend using an OpenAI model as the preferred option. Users can easily add their own OpenAI API key ~~via the mobile app~~ in the environment variables, see [[Environment_Variables]], enabling them to leverage the full reliability of OpenAI's models. The local LLM should only be used as a last resort, particularly due to the lower reliability and performance issues we encountered.


# Environment variables

- ## Frontend
  - KEYCLOAK_BASE_URL: Start of the Keycloak url appended before any calls made to Keycloak. Example for local development: "http://localhost:8180"
  - KEYCLOAK_CLIENT_ID: Name of your Keycloak client. Example: "flutter-app"
  - KEYCLOAK_REALM: Name of your Keycloak realm. Example: "culinary-code-dev-realm"
  - BACKEND_BASE_URL: Start of the backend url appended before any calls made to the backend api endpoints. Example for local development: "https://localhost:7098"
  - DEVELOPMENT_MODE: A boolean "true" or "false" as strings which will switch the frontend to less safer http calls instead of https with simplified login steps to make development for the app way easier. DO NOT LEAVE THIS ON "false" IN DEPLOYMENT!
  
- ## Backend
  - ASPNETCORE_ENVIRONMENT=Development;                         # Development, Staging, Production
  - ASPNETCORE_HTTPS_PORT=443;   
  - ASPNETCORE_URLS=https://0.0.0.0:7098\;http://0.0.0.0:5114;
  - AzureOpenAI__ApiKey={YOUR_API_KEY};                         # Azure OpenAI Service API key
  - AzureOpenAI__Endpoint={YOUR_ENDPOINT};                      # Azure OpenAI Service endpoint  
  - AzureStorage__ConnectionString={YOUR_CONNECTION_STRING};    # Azure Blog Storage connection string for saving recipe images
  - AzureStorage__ContainerName={YOUR_CONTAINER_NAME};          # Azure Blog Storage container name for saving recipe images
  - Database__ConnectionString={YOUR_CONNECTION_STRING};        # PostgreSQL connection string
  - Keycloak__AdminPassword={YOUR_PASSWORD};                    # Keycloak admin password
  - Keycloak__AdminUsername={YOUR_USERNAME};                    # Keycloak admin username (only used for local development)
  - Keycloak__BaseUrl=http://localhost:8180;                    # Keycloak base URL
  - Keycloak__ClientId={YOUR_CLIENT_ID};                        # Keycloak client ID
  - Keycloak__FrontendUrl=http://localhost:8180;                # Keycloak frontend URL in case the issuer URL is different than the base URL
  - Keycloak__Realm={YOUR_REALM};                               # Keycloak realm
  - LocalLlmServer__ServerUrl=http://localhost:4891;            # Local LLM server URL
  - RecipeJob__CronSchedule=0 0 2 * * ?;                        # Cron schedule for recipe generation job
  - RecipeJob__MinAmount=5                                      # Minimum amount of recipes to maintain in the database, if the amount is lower, the recipe generation job will be triggered at the scheduled time
  - EmailService__SmtpClient                                    # Client used for sending invitation emails. Example:"smtp.gmail.com"
  - EmailService__SmtpPassword                                  # Password corresponding to the smtpUserName
  - EmailService__SmtpUserName                                  # SmptpUsername. Example:"noreply.test@gmail.com"


# Frontend

## Technology Evaluation and Choice for Frontend Development

When deciding on the technology for the frontend of our application, we conducted a thorough evaluation of several frameworks and languages. Below is an overview of the options we considered and the reasoning behind our final decision.

---

### **Evaluation of Frontend Technologies**

#### **Flutter**
- **Cross-platform:** Enables development for both Android and iOS from a single codebase.
- **Extensive Documentation:** Comprehensive resources for learning and troubleshooting.
- **Challenging but Rewarding:** A relatively new technology for our team, providing both a learning opportunity and a challenge.
- **Complex UI Components:** Supports building intricate and visually consistent user interfaces.

#### **React Native**
- **Limited Framework:** Offers fewer built-in capabilities compared to Flutter.
- **Familiarity:** Similar to React, which some team members already know.
- **Native Component Differences:** Potential variations in behavior and appearance between Android and iOS due to reliance on native components.

#### **Kotlin**
- **Cross-platform Potential:** Supports cross-platform development, particularly through Kotlin Multiplatform.
- **Java-like Syntax:** Familiar to developers with a Java background.
- **Ease of Learning:** Straightforward for developers with Java experience.

---

### **Our Choice: Flutter**

After evaluating the available options, we chose **Flutter** for the following reasons:

1. **Cross-Platform Consistency:**  
   Our goal is to create a cross-platform application with a consistent look and feel on both Android and iOS. Flutter excels at ensuring visual and functional parity across platforms.

2. **Complex UI Requirements:**  
   Flutter is highly recommended for developing complex and dynamic user interfaces, which aligns with the needs of our application.

3. **Team Learning Opportunity:**  
   While Flutter is a new technology for our team, this challenge presents a valuable learning opportunity. Adopting Flutter allows us to gain experience in a modern and versatile framework.

4. **Comparison with Other Options:**
   - Jetpack Compose (Kotlin) was ruled out due to its limited cross-platform capabilities.
   - Kotlin, while easy to learn, lacks widespread internal support within our organization.
   - React Native, though familiar to some, has limitations in consistency across platforms and fewer built-in capabilities compared to Flutter.

---

By choosing Flutter, we are embracing a robust framework that not only meets our technical needs but also supports our team's growth. We are confident this decision will contribute to a high-quality application and a positive development experience.


# Backend

## Technology Evaluation and Choice for Backend Development

For the backend of our application, we carefully evaluated multiple languages and frameworks to select the best fit for our technical and deployment needs. Below is a summary of the options considered and the reasoning behind our decision.

---

### **Evaluation of Backend Technologies**

#### **Java**
- **Robust:** A mature and widely-used language with proven stability.
- **Extensive Support:** Backed by a large developer community and abundant resources.
- **Compatibility with Kotlin:** Shares similarities with Kotlin, offering flexibility if we choose to expand or switch in the future.

#### **.NET**
- **Optimized for Azure:** Designed to integrate seamlessly with Azure, Microsoft's cloud platform.
- **Efficient Data Processing:** Known for strong performance when handling large data sets.
- **NuGet Packages:** Provides excellent Azure-related libraries and tools for streamlined deployment and integration.

---

### **Our Choice: .NET**

We chose **.NET** as the backend framework for the following reasons:

1. **Azure Deployment:**  
   We will work with an Azure environment for hosting the application. As both .NET and Azure are Microsoft products, the synergy between the two ensures a smooth and efficient deployment process using well-supported NuGet packages.

2. **Comparable Performance to Java:**  
   Both Java and .NET offer comparable performance, making the choice largely dependent on other factors. Given .NET's Azure compatibility, it was the logical option.

3. **Ease of Integration:**  
   .NET simplifies the integration of Azure's services, saving time and effort in building and deploying the application.

---

By choosing .NET, we align our backend development with Azure's capabilities and ensure a robust, high-performance application. This decision leverages the strengths of Microsoft's ecosystem to deliver a seamless development and deployment experience.

# Roadmap

# Known Bugs

# Licences
  - Apache2.0
  - Moq diff license

# How to 

- ## Set the project up

- ## Pull Request

- ## Report Bugs

- ## Ask questions
