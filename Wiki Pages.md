# How to set the project up

# Keycloak

- ## Set up

- ## Necessary Users

# Deploying to Azure

- ## Image generator

- ## GPT

- ## Blob storage

- ## Database

# Running everything locally

## Recommended LLM Model

After extensive testing, we recommend using the GPT-4o Mini model (version: 2024-07-18) for this project. This model has consistently delivered reliable and accurate results, meeting our specific requirements.

While we also tested GPT-3.5 Turbo, we found its reliability to be significantly lower, particularly in non-English languages. Since our development and testing focus on a Dutch-speaking user base, the GPT-4o Mini model proved far superior in handling these language-specific needs.

Additionally, we tested several local LLMs, but found that the output from smaller models was not reliable, with significant inconsistencies in performance. Larger models might offer better reliability, but they require significantly higher computational resources. Running them efficiently would demand high-end hardware, which may not be practical for all setups.

For users opting for local hosting, we recommend using an OpenAI model as the preferred option. Users can easily add their own OpenAI API key via the mobile app, enabling them to leverage the full reliability of OpenAI's models. The local LLM should only be used as a last resort, particularly due to the lower reliability and performance issues we encountered.


# Environment variables

- ## Frontend

- ## Backend

# Frontend

# Backend

# Roadmap

# Known Bugs

# Licenties

# How to 

- ## Pull Request

- ## Report Bugs

- ## Ask questions
